{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, argparse, json\n",
    "import torch.nn as nn # layer types\n",
    "import torch.nn.functional as func # useful ML functions (activations) that are applied to layers\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "# Ex_A = np.loadtxt(fname=\"data/a.txt\", dtype='int')\n",
    "# Ex_B = np.loadtxt(fname=\"data/b.txt\", dtype='int')\n",
    "# Ex_C = np.loadtxt(fname=\"data/c.txt\", dtype='int')\n",
    "\n",
    "# print(Ex_A,\"\\n\")\n",
    "# print(Ex_B,\"\\n\")\n",
    "# print(Ex_C)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "display_epochs = 10\n",
    "test_size = 10000 #final of 10,000\n",
    "train_size = 1000 # final of 1,000\n",
    "seed = 492 #can be whatever, just remember it\n",
    "nhidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-96d6dfc7743c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdata_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'A tensor shape: {data_a.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-226-96d6dfc7743c>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(test_size, train_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mformat_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:0'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_len\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=seed)\n",
    "#data_x = []\n",
    "\n",
    "def create_dataset(test_size,train_size):\n",
    "    in_len = 8\n",
    "    out_len = 16\n",
    "    size = test_size+train_size\n",
    "    max_int = 2**(in_len-1)\n",
    "    format_in = '{:0' + str(in_len) + 'b}'\n",
    "    format_out = '{:0' + str(out_len) + 'b}'\n",
    "    \n",
    "    A = np.zeros((size, in_len))\n",
    "    B = np.zeros((size, in_len))\n",
    "    C = np.zeros((size, out_len))\n",
    "    \n",
    "    for i in range(size):\n",
    "        int_a = np.random.randint(0, max_int)\n",
    "        int_b = np.random.randint(0, max_int)\n",
    "        \n",
    "        A[i,:] = list(reversed([int(b) for b in format_in.format(int_a)]))\n",
    "        B[i,:] = list(reversed([int(b) for b in format_in.format(int_b)]))\n",
    "        C[i,:] = list([int(b) for b in format_out.format(int_a*int_b)])\n",
    "    return A, B, C\n",
    "\n",
    "data_a, data_b, data_c = create_dataset(test_size,train_size)\n",
    "data_x = np.append(data_a,data_b, axis=1)\n",
    "print(f'A tensor shape: {data_a.shape}')\n",
    "print(f'B tensor shape: {data_b.shape}')\n",
    "print(f'C tensor shape: {data_c.shape}')\n",
    "print(f'X tensor shape: {data_x.shape}')\n",
    "\n",
    "print('\\n'+ str(data_a[1]))\n",
    "print(data_b[1])\n",
    "print(data_x[1:4])\n",
    "\n",
    "x_train = data_x[:-train_size]\n",
    "x_test = data_x[-train_size:]\n",
    "c_train = data_c[:-train_size]\n",
    "c_test = data_c[-train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiplier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multiplier, self).__init__() \n",
    "        self.rnn= nn.RNN(16, nhidden)\n",
    "        self.lin= nn.Linear(nhidden, 16) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        rnnOut,_=self.rnn(x)\n",
    "        h = func.relu(rnnOut)\n",
    "        y = func.sigmoid(self.lin(h))\n",
    "        return y\n",
    "    \n",
    "    def reset(self):\n",
    "        self.rnn.reset_parameters()\n",
    "        self.lin.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multiplier().to(torch.device(\"cpu\"))\n",
    "loss = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = torch.from_numpy(c_train)\n",
    "# targets = targets.contiguous()\n",
    "# print(targets.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test in one loop\n",
    "obj_vals= []\n",
    "obj_accs= []\n",
    "cross_vals= []\n",
    "cross_accs= []\n",
    "\n",
    "model.reset() # reset your parameters\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Training\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(c_train)\n",
    "    #targets = torch.reshape(targets, (-1, 1))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    inputs = autograd.Variable(inputs.unsqueeze(1).float())\n",
    "    seqLen = inputs.size(0)\n",
    "    inputs = inputs.contiguous()\n",
    "    inputs = model(inputs)\n",
    "    \n",
    "    targets = autograd.Variable(targets.unsqueeze(1).float())\n",
    "    #targets = targets.type(torch.LongTensor)\n",
    "\n",
    "    obj_val = loss(inputs, targets)\n",
    "    obj_vals.append(obj_val.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    obj_val.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    if (epoch+1) % display_epochs == 0:\n",
    "        print ('Epoch [{}/{}]\\t Training Loss: {:.4f}'.format(epoch+1, epochs, obj_val.item()))\n",
    "    \n",
    "    #Checking loss at each step to compare\n",
    "    with torch.no_grad(): \n",
    "        # don't track calculations in the following scope for the purposes of gradients\n",
    "        inputs = torch.from_numpy(x_test)\n",
    "        targets = torch.from_numpy(c_test)\n",
    "        #targets = torch.reshape(targets, (-1, 1))\n",
    "        \n",
    "        inputs = autograd.Variable(inputs.unsqueeze(1).float())\n",
    "        seqLen = inputs.size(0)\n",
    "        inputs = inputs.contiguous()\n",
    "        inputs = model(inputs)\n",
    "#         inputs = inputs.argmax(2)\n",
    "#         print(inputs[epoch,0,0])\n",
    "        targets = autograd.Variable(targets.unsqueeze(1).float())\n",
    "        #targets = targets.type(torch.LongTensor)\n",
    "#         targets = targets.argmax(2)\n",
    "        correct = 0\n",
    "        for i in range(16):\n",
    "            if inputs[epoch,0,i]>0.5:\n",
    "                 inputs[epoch,0,i] =1\n",
    "            else:\n",
    "                inputs[epoch,0,i] =0\n",
    "                \n",
    "            if targets[epoch,0,i]>0.5:\n",
    "                 targets[epoch,0,i] =1\n",
    "            else:\n",
    "                targets[epoch,0,i] =0\n",
    "                \n",
    "            if inputs[epoch,0,i]==targets[epoch,0,i]:\n",
    "                correct+=1\n",
    "    \n",
    "        cross_val = loss(inputs, targets)\n",
    "        cross_vals.append(cross_val)\n",
    "        cross_accs.append(100*correct/16)\n",
    "        \n",
    "\n",
    "    if (epoch+1) % display_epochs == 0:\n",
    "        print ('Epoch [{}/{}]\\t Test Loss: {:.4f}'.format(epoch+1, epochs, cross_val.item()))\n",
    "        print ('Epoch [{}/{}]\\t Test Accuracy: {:.4f}%'.format(epoch+1, epochs, np.average(cross_accs)))\n",
    "        print ('Target:', targets[epoch])\n",
    "        print ('Trained:', inputs[epoch],'\\n')\n",
    "        \n",
    "print('Final training loss: {:.4f}'.format(obj_vals[-1]))\n",
    "print('Final testing performance: \\n Loss: {:.4f} \\t Accuracy: {:0.2f}%'.format(cross_vals[-1],np.average(cross_accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
